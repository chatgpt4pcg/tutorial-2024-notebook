{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install llm4pcg",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing the packages",
   "id": "b6d193a0bafa7829"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from llm4pcg.competition import chat_with_llm, run_evaluation\n",
    "from llm4pcg.models.trial_context import TrialContext\n",
    "from llm4pcg.models.trial_loop import TrialLoop"
   ],
   "id": "82a8d99ec8017f59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "6523ef84b75bd65e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "CHARACTERS = [\"A\", \"B\", \"C\"] # Change this to the list of target you want to evaluate. Reduce number of characters for faster testing.\n",
    "NUM_TRIALS = 3 # Adjust the number of trials as needed. You may want to lower it for faster testing.\n",
    "MODEL_NAME = \"<PUT_YOUR_MODEL_NAME_HERE>\" # TODO: Change the model name if necessary\n",
    "LOCAL_MODEL_BASE_URL = \"http://localhost:1234/v1\" # TODO: Change the port if necessary"
   ],
   "id": "98fe946b1693e13f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Helper system prompt for improving structured output generation\n",
    "SYSTEM_PROMPT = \"Output in Markdown code block format (between ``` and ```). The last code block must contain all the \\\n",
    "necessary code required to produce a level. Output only the 'drop_block' function with proper arguments, without any \\\n",
    "other code. You do not need to define the 'drop_block' function or any other functions.\""
   ],
   "id": "15cd1e28e35bbd3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zero-Shot Prompting",
   "id": "bf811d1109cdea4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ZeroShotPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the zero-shot prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        prompt_template = open(Path(\"prompts/task-zero-shot.txt\"), \"r\").read()\n",
    "\n",
    "        responses = chat_with_llm(ctx, [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_template.format(\n",
    "                object=target_character\n",
    "            )}])\n",
    "\n",
    "        response = responses[0]\n",
    "        return response"
   ],
   "id": "70db0c474748f167",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_evaluation(\"zero_shot\", ZeroShotPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "bba35064c6b1fa78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zero-Shot Chain-of-Thought Prompting",
   "id": "9c99b566394799b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ZeroShotCoTPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the zero-shot chain-of-thought prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        prompt_template = open(Path(\"prompts/task-zero-shot-cot.txt\"), \"r\").read()\n",
    "\n",
    "        responses = chat_with_llm(ctx, [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_template.format(\n",
    "                object=target_character\n",
    "            )}])\n",
    "\n",
    "        response = responses[0]\n",
    "        return response"
   ],
   "id": "508a28d944e3154d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_evaluation(\"zero_shot_cot\", ZeroShotCoTPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "50b8b0af58f7bf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Few-Shot Prompting",
   "id": "2c9435ac16743c99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class FewShotPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the few-shot prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        prompt_template = open(Path(\"prompts/task-few-shot.txt\"), \"r\").read()\n",
    "\n",
    "        responses = chat_with_llm(ctx, [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_template.format(\n",
    "                object=target_character\n",
    "            )}])\n",
    "\n",
    "        response = responses[0]\n",
    "        return response"
   ],
   "id": "1a78c69320bb52e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_evaluation(\"few_shot\", FewShotPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "a2a3ac69c3e2cec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tree-of-Thought Prompting",
   "id": "1dfe217100dcbbee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TreeOfThoughtPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def extract_scores(scores_str: str):\n",
    "        scores_str = scores_str.lower()\n",
    "        stability_pattern = r\".*stability: (10|\\d).*\"\n",
    "        similarity_pattern = r\".*similarity: (10|\\d).*\"\n",
    "        stability = 0\n",
    "        similarity = 0\n",
    "        if stability_match := re.search(stability_pattern, scores_str):\n",
    "            stability = int(stability_match.group(1))\n",
    "        if similarity_match := re.search(similarity_pattern, scores_str):\n",
    "            similarity = int(similarity_match.group(1))\n",
    "        return stability, similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def tot(ctx: TrialContext, target_character: str) -> str:\n",
    "        max_depth = 2\n",
    "        branching_factor = 2\n",
    "\n",
    "        current_content = \"\"\n",
    "\n",
    "        # TODO: Implement this function\n",
    "        # Loop until reaching the maximum depth\n",
    "        # | 1. Perform the task to generate {branching_factor} thoughts\n",
    "        # | 2. Evaluate each thought and select the best one\n",
    "        # | 3. Repeat the process with the selected thought\n",
    "        # Format the final response in a correct format and return it\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the tree-of-thought prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        final_response = TreeOfThoughtPrompting.tot(ctx, target_character)\n",
    "\n",
    "        return final_response"
   ],
   "id": "712b60182359a56e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "run_evaluation(\"tot\", TreeOfThoughtPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "6e5260bf3a2f3cb0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
