{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T03:56:11.240115Z",
     "start_time": "2024-07-11T03:56:07.380071Z"
    }
   },
   "source": "!pip install llm4pcg",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llm4pcg\r\n",
      "  Using cached llm4pcg-1.0.1-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting openai (from llm4pcg)\r\n",
      "  Downloading openai-1.35.13-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/pittawat/dev/miniconda3/envs/cog-tutorial/lib/python3.12/site-packages (from openai->llm4pcg) (4.2.0)\r\n",
      "Collecting distro<2,>=1.7.0 (from openai->llm4pcg)\r\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting httpx<1,>=0.23.0 (from openai->llm4pcg)\r\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->llm4pcg)\r\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\r\n",
      "\u001B[2K     \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m125.2/125.2 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: sniffio in /Users/pittawat/dev/miniconda3/envs/cog-tutorial/lib/python3.12/site-packages (from openai->llm4pcg) (1.3.0)\r\n",
      "Collecting tqdm>4 (from openai->llm4pcg)\r\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/pittawat/dev/miniconda3/envs/cog-tutorial/lib/python3.12/site-packages (from openai->llm4pcg) (4.11.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pittawat/dev/miniconda3/envs/cog-tutorial/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->llm4pcg) (3.7)\r\n",
      "Requirement already satisfied: certifi in /Users/pittawat/dev/miniconda3/envs/cog-tutorial/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->llm4pcg) (2024.7.4)\r\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->llm4pcg)\r\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->llm4pcg)\r\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\r\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai->llm4pcg)\r\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1.9.0->openai->llm4pcg)\r\n",
      "  Downloading pydantic_core-2.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\r\n",
      "Using cached llm4pcg-1.0.1-py3-none-any.whl (7.3 kB)\r\n",
      "Downloading openai-1.35.13-py3-none-any.whl (328 kB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m328.5/328.5 kB\u001B[0m \u001B[31m14.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\r\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\r\n",
      "Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m423.9/423.9 kB\u001B[0m \u001B[31m32.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading pydantic_core-2.20.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m39.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mm eta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached tqdm-4.66.4-py3-none-any.whl (78 kB)\r\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\r\n",
      "Installing collected packages: tqdm, pydantic-core, h11, distro, annotated-types, pydantic, httpcore, httpx, openai, llm4pcg\r\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llm4pcg-1.0.1 openai-1.35.13 pydantic-2.8.2 pydantic-core-2.20.1 tqdm-4.66.4\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing the packages",
   "id": "b6d193a0bafa7829"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T04:01:14.136330Z",
     "start_time": "2024-07-11T04:01:14.134102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llm4pcg.competition import chat_with_llm, run_evaluation\n",
    "from llm4pcg.models.trial_context import TrialContext\n",
    "from llm4pcg.models.trial_loop import TrialLoop"
   ],
   "id": "82a8d99ec8017f59",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "6523ef84b75bd65e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T03:58:11.134493Z",
     "start_time": "2024-07-11T03:58:11.132570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHARACTERS = [\"A\", \"B\", \"C\"]\n",
    "NUM_TRIALS = 3\n",
    "MODEL_NAME = \"<PUT_YOUR_MODEL_NAME_HERE>\"\n",
    "LOCAL_MODEL_BASE_URL = \"http://localhost:3000/v1\""
   ],
   "id": "98fe946b1693e13f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T03:58:12.235465Z",
     "start_time": "2024-07-11T03:58:12.233348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SYSTEM_PROMPT = \"Output in Markdown code block format (between ``` and ```). The last code block must contain all the \\\n",
    "necessary code required to produce a level. Output only the 'drop_block' function with proper arguments, without any \\\n",
    "other code. You do not need to define the 'drop_block' function or any other functions.\""
   ],
   "id": "15cd1e28e35bbd3a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zero-Shot Prompting",
   "id": "bf811d1109cdea4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T03:58:56.950748Z",
     "start_time": "2024-07-11T03:58:56.947269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ZeroShotPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the zero-shot prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        prompt_template = open(Path(\"prompts/task-zero-shot.txt\"), \"r\").read()\n",
    "\n",
    "        responses = chat_with_llm(ctx, [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_template.format(\n",
    "                object=target_character\n",
    "            )}])\n",
    "\n",
    "        response = responses[0]\n",
    "        return response"
   ],
   "id": "70db0c474748f167",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T04:00:44.622977Z",
     "start_time": "2024-07-11T04:00:08.740281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_evaluation(\"zero_shot\", ZeroShotPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "bba35064c6b1fa78",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zero-Shot Chain-of-Thought Prompting",
   "id": "9c99b566394799b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T04:02:23.152563Z",
     "start_time": "2024-07-11T04:02:23.149091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ZeroShotCoTPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the zero-shot chain-of-thought prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        prompt_template = open(Path(\"prompts/task-zero-shot-cot.txt\"), \"r\").read()\n",
    "\n",
    "        responses = chat_with_llm(ctx, [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_template.format(\n",
    "                object=target_character\n",
    "            )}])\n",
    "\n",
    "        response = responses[0]\n",
    "        return response"
   ],
   "id": "508a28d944e3154d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T04:03:04.962414Z",
     "start_time": "2024-07-11T04:02:32.717636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_evaluation(\"zero_shot_cot\", ZeroShotCoTPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "50b8b0af58f7bf8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Few-Shot Prompting",
   "id": "2c9435ac16743c99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T04:03:04.965227Z",
     "start_time": "2024-07-11T04:03:04.963269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FewShotPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the few-shot prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        prompt_template = open(Path(\"prompts/task-few-shot.txt\"), \"r\").read()\n",
    "\n",
    "        responses = chat_with_llm(ctx, [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt_template.format(\n",
    "                object=target_character\n",
    "            )}])\n",
    "\n",
    "        response = responses[0]\n",
    "        return response"
   ],
   "id": "1a78c69320bb52e2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T04:03:54.010049Z",
     "start_time": "2024-07-11T04:03:04.965695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_evaluation(\"few_shot\", FewShotPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "a2a3ac69c3e2cec8",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tree-of-Thought Prompting",
   "id": "1dfe217100dcbbee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TreeOfThoughtPrompting(TrialLoop):\n",
    "    @staticmethod\n",
    "    def extract_scores(scores_str: str):\n",
    "        import re\n",
    "        scores_str = scores_str.lower()\n",
    "        stability_pattern = r\".*stability: (10|\\d).*\"\n",
    "        similarity_pattern = r\".*similarity: (10|\\d).*\"\n",
    "        stability = 0\n",
    "        similarity = 0\n",
    "        if stability_match := re.search(stability_pattern, scores_str):\n",
    "            stability = int(stability_match.group(1))\n",
    "        if similarity_match := re.search(similarity_pattern, scores_str):\n",
    "            similarity = int(similarity_match.group(1))\n",
    "        return stability, similarity\n",
    "\n",
    "    @staticmethod\n",
    "    def tot(ctx: TrialContext, target_character: str) -> str:\n",
    "        max_depth = 2\n",
    "        branching_factor = 2\n",
    "\n",
    "        current_content = \"\"\n",
    "\n",
    "        # TODO: Implement this\n",
    "        # Loop until reaching the maximum depth\n",
    "        # | 1. Perform the task to generate {branching_factor} thoughts\n",
    "        # | 2. Evaluate each thought and select the best one\n",
    "        # | 3. Repeat the process with the selected thought\n",
    "        # Format the final response in a correct format and return it\n",
    "\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def run(ctx: TrialContext, target_character: str) -> str:\n",
    "        \"\"\"\n",
    "        Runs the tree-of-thought prompting.\n",
    "        :param ctx: The trial context.\n",
    "        :param target_character: The target character.\n",
    "        :return: The generated text.\n",
    "        \"\"\"\n",
    "        final_response = TreeOfThoughtPrompting.tot(ctx, target_character)\n",
    "\n",
    "        return final_response"
   ],
   "id": "712b60182359a56e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T04:26:06.485859Z",
     "start_time": "2024-07-11T04:19:20.502272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_evaluation(\"tot\", TreeOfThoughtPrompting, characters=CHARACTERS, num_trials=NUM_TRIALS,\n",
    "               model_name=MODEL_NAME, local_model_base_url=LOCAL_MODEL_BASE_URL)"
   ],
   "id": "6e5260bf3a2f3cb0",
   "outputs": [],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
